{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00e+00 5.10e+00 3.50e+00 1.40e+00 2.00e-01 0.00e+00]\n",
      " [2.00e+00 4.90e+00 3.00e+00 1.40e+00 2.00e-01 0.00e+00]\n",
      " [3.00e+00 4.70e+00 3.20e+00 1.30e+00 2.00e-01 0.00e+00]\n",
      " [4.00e+00 4.60e+00 3.10e+00 1.50e+00 2.00e-01 0.00e+00]\n",
      " [5.00e+00 5.00e+00 3.60e+00 1.40e+00 2.00e-01 0.00e+00]\n",
      " [6.00e+00 5.40e+00 3.90e+00 1.70e+00 4.00e-01 0.00e+00]\n",
      " [7.00e+00 4.60e+00 3.40e+00 1.40e+00 3.00e-01 0.00e+00]\n",
      " [8.00e+00 5.00e+00 3.40e+00 1.50e+00 2.00e-01 0.00e+00]\n",
      " [9.00e+00 4.40e+00 2.90e+00 1.40e+00 2.00e-01 0.00e+00]\n",
      " [1.00e+01 4.90e+00 3.10e+00 1.50e+00 1.00e-01 0.00e+00]\n",
      " [1.10e+01 5.40e+00 3.70e+00 1.50e+00 2.00e-01 0.00e+00]\n",
      " [1.20e+01 4.80e+00 3.40e+00 1.60e+00 2.00e-01 0.00e+00]\n",
      " [1.30e+01 4.80e+00 3.00e+00 1.40e+00 1.00e-01 0.00e+00]\n",
      " [1.40e+01 4.30e+00 3.00e+00 1.10e+00 1.00e-01 0.00e+00]\n",
      " [1.50e+01 5.80e+00 4.00e+00 1.20e+00 2.00e-01 0.00e+00]\n",
      " [1.60e+01 5.70e+00 4.40e+00 1.50e+00 4.00e-01 0.00e+00]\n",
      " [1.70e+01 5.40e+00 3.90e+00 1.30e+00 4.00e-01 0.00e+00]\n",
      " [1.80e+01 5.10e+00 3.50e+00 1.40e+00 3.00e-01 0.00e+00]\n",
      " [1.90e+01 5.70e+00 3.80e+00 1.70e+00 3.00e-01 0.00e+00]\n",
      " [2.00e+01 5.10e+00 3.80e+00 1.50e+00 3.00e-01 0.00e+00]\n",
      " [2.10e+01 5.40e+00 3.40e+00 1.70e+00 2.00e-01 0.00e+00]\n",
      " [2.20e+01 5.10e+00 3.70e+00 1.50e+00 4.00e-01 0.00e+00]\n",
      " [2.30e+01 4.60e+00 3.60e+00 1.00e+00 2.00e-01 0.00e+00]\n",
      " [2.40e+01 5.10e+00 3.30e+00 1.70e+00 5.00e-01 0.00e+00]\n",
      " [2.50e+01 4.80e+00 3.40e+00 1.90e+00 2.00e-01 0.00e+00]\n",
      " [2.60e+01 5.00e+00 3.00e+00 1.60e+00 2.00e-01 0.00e+00]\n",
      " [2.70e+01 5.00e+00 3.40e+00 1.60e+00 4.00e-01 0.00e+00]\n",
      " [2.80e+01 5.20e+00 3.50e+00 1.50e+00 2.00e-01 0.00e+00]\n",
      " [2.90e+01 5.20e+00 3.40e+00 1.40e+00 2.00e-01 0.00e+00]\n",
      " [3.00e+01 4.70e+00 3.20e+00 1.60e+00 2.00e-01 0.00e+00]\n",
      " [3.10e+01 4.80e+00 3.10e+00 1.60e+00 2.00e-01 0.00e+00]\n",
      " [3.20e+01 5.40e+00 3.40e+00 1.50e+00 4.00e-01 0.00e+00]\n",
      " [3.30e+01 5.20e+00 4.10e+00 1.50e+00 1.00e-01 0.00e+00]\n",
      " [3.40e+01 5.50e+00 4.20e+00 1.40e+00 2.00e-01 0.00e+00]\n",
      " [3.50e+01 4.90e+00 3.10e+00 1.50e+00 1.00e-01 0.00e+00]\n",
      " [3.60e+01 5.00e+00 3.20e+00 1.20e+00 2.00e-01 0.00e+00]\n",
      " [3.70e+01 5.50e+00 3.50e+00 1.30e+00 2.00e-01 0.00e+00]\n",
      " [3.80e+01 4.90e+00 3.10e+00 1.50e+00 1.00e-01 0.00e+00]\n",
      " [3.90e+01 4.40e+00 3.00e+00 1.30e+00 2.00e-01 0.00e+00]\n",
      " [4.00e+01 5.10e+00 3.40e+00 1.50e+00 2.00e-01 0.00e+00]\n",
      " [4.10e+01 5.00e+00 3.50e+00 1.30e+00 3.00e-01 0.00e+00]\n",
      " [4.20e+01 4.50e+00 2.30e+00 1.30e+00 3.00e-01 0.00e+00]\n",
      " [4.30e+01 4.40e+00 3.20e+00 1.30e+00 2.00e-01 0.00e+00]\n",
      " [4.40e+01 5.00e+00 3.50e+00 1.60e+00 6.00e-01 0.00e+00]\n",
      " [4.50e+01 5.10e+00 3.80e+00 1.90e+00 4.00e-01 0.00e+00]\n",
      " [4.60e+01 4.80e+00 3.00e+00 1.40e+00 3.00e-01 0.00e+00]\n",
      " [4.70e+01 5.10e+00 3.80e+00 1.60e+00 2.00e-01 0.00e+00]\n",
      " [4.80e+01 4.60e+00 3.20e+00 1.40e+00 2.00e-01 0.00e+00]\n",
      " [4.90e+01 5.30e+00 3.70e+00 1.50e+00 2.00e-01 0.00e+00]\n",
      " [5.00e+01 5.00e+00 3.30e+00 1.40e+00 2.00e-01 0.00e+00]\n",
      " [5.10e+01 7.00e+00 3.20e+00 4.70e+00 1.40e+00 1.00e+00]\n",
      " [5.20e+01 6.40e+00 3.20e+00 4.50e+00 1.50e+00 1.00e+00]\n",
      " [5.30e+01 6.90e+00 3.10e+00 4.90e+00 1.50e+00 1.00e+00]\n",
      " [5.40e+01 5.50e+00 2.30e+00 4.00e+00 1.30e+00 1.00e+00]\n",
      " [5.50e+01 6.50e+00 2.80e+00 4.60e+00 1.50e+00 1.00e+00]\n",
      " [5.60e+01 5.70e+00 2.80e+00 4.50e+00 1.30e+00 1.00e+00]\n",
      " [5.70e+01 6.30e+00 3.30e+00 4.70e+00 1.60e+00 1.00e+00]\n",
      " [5.80e+01 4.90e+00 2.40e+00 3.30e+00 1.00e+00 1.00e+00]\n",
      " [5.90e+01 6.60e+00 2.90e+00 4.60e+00 1.30e+00 1.00e+00]\n",
      " [6.00e+01 5.20e+00 2.70e+00 3.90e+00 1.40e+00 1.00e+00]\n",
      " [6.10e+01 5.00e+00 2.00e+00 3.50e+00 1.00e+00 1.00e+00]\n",
      " [6.20e+01 5.90e+00 3.00e+00 4.20e+00 1.50e+00 1.00e+00]\n",
      " [6.30e+01 6.00e+00 2.20e+00 4.00e+00 1.00e+00 1.00e+00]\n",
      " [6.40e+01 6.10e+00 2.90e+00 4.70e+00 1.40e+00 1.00e+00]\n",
      " [6.50e+01 5.60e+00 2.90e+00 3.60e+00 1.30e+00 1.00e+00]\n",
      " [6.60e+01 6.70e+00 3.10e+00 4.40e+00 1.40e+00 1.00e+00]\n",
      " [6.70e+01 5.60e+00 3.00e+00 4.50e+00 1.50e+00 1.00e+00]\n",
      " [6.80e+01 5.80e+00 2.70e+00 4.10e+00 1.00e+00 1.00e+00]\n",
      " [6.90e+01 6.20e+00 2.20e+00 4.50e+00 1.50e+00 1.00e+00]\n",
      " [7.00e+01 5.60e+00 2.50e+00 3.90e+00 1.10e+00 1.00e+00]\n",
      " [7.10e+01 5.90e+00 3.20e+00 4.80e+00 1.80e+00 1.00e+00]\n",
      " [7.20e+01 6.10e+00 2.80e+00 4.00e+00 1.30e+00 1.00e+00]\n",
      " [7.30e+01 6.30e+00 2.50e+00 4.90e+00 1.50e+00 1.00e+00]\n",
      " [7.40e+01 6.10e+00 2.80e+00 4.70e+00 1.20e+00 1.00e+00]\n",
      " [7.50e+01 6.40e+00 2.90e+00 4.30e+00 1.30e+00 1.00e+00]\n",
      " [7.60e+01 6.60e+00 3.00e+00 4.40e+00 1.40e+00 1.00e+00]\n",
      " [7.70e+01 6.80e+00 2.80e+00 4.80e+00 1.40e+00 1.00e+00]\n",
      " [7.80e+01 6.70e+00 3.00e+00 5.00e+00 1.70e+00 1.00e+00]\n",
      " [7.90e+01 6.00e+00 2.90e+00 4.50e+00 1.50e+00 1.00e+00]\n",
      " [8.00e+01 5.70e+00 2.60e+00 3.50e+00 1.00e+00 1.00e+00]\n",
      " [8.10e+01 5.50e+00 2.40e+00 3.80e+00 1.10e+00 1.00e+00]\n",
      " [8.20e+01 5.50e+00 2.40e+00 3.70e+00 1.00e+00 1.00e+00]\n",
      " [8.30e+01 5.80e+00 2.70e+00 3.90e+00 1.20e+00 1.00e+00]\n",
      " [8.40e+01 6.00e+00 2.70e+00 5.10e+00 1.60e+00 1.00e+00]\n",
      " [8.50e+01 5.40e+00 3.00e+00 4.50e+00 1.50e+00 1.00e+00]\n",
      " [8.60e+01 6.00e+00 3.40e+00 4.50e+00 1.60e+00 1.00e+00]\n",
      " [8.70e+01 6.70e+00 3.10e+00 4.70e+00 1.50e+00 1.00e+00]\n",
      " [8.80e+01 6.30e+00 2.30e+00 4.40e+00 1.30e+00 1.00e+00]\n",
      " [8.90e+01 5.60e+00 3.00e+00 4.10e+00 1.30e+00 1.00e+00]\n",
      " [9.00e+01 5.50e+00 2.50e+00 4.00e+00 1.30e+00 1.00e+00]\n",
      " [9.10e+01 5.50e+00 2.60e+00 4.40e+00 1.20e+00 1.00e+00]\n",
      " [9.20e+01 6.10e+00 3.00e+00 4.60e+00 1.40e+00 1.00e+00]\n",
      " [9.30e+01 5.80e+00 2.60e+00 4.00e+00 1.20e+00 1.00e+00]\n",
      " [9.40e+01 5.00e+00 2.30e+00 3.30e+00 1.00e+00 1.00e+00]\n",
      " [9.50e+01 5.60e+00 2.70e+00 4.20e+00 1.30e+00 1.00e+00]\n",
      " [9.60e+01 5.70e+00 3.00e+00 4.20e+00 1.20e+00 1.00e+00]\n",
      " [9.70e+01 5.70e+00 2.90e+00 4.20e+00 1.30e+00 1.00e+00]\n",
      " [9.80e+01 6.20e+00 2.90e+00 4.30e+00 1.30e+00 1.00e+00]\n",
      " [9.90e+01 5.10e+00 2.50e+00 3.00e+00 1.10e+00 1.00e+00]\n",
      " [1.00e+02 5.70e+00 2.80e+00 4.10e+00 1.30e+00 1.00e+00]\n",
      " [1.01e+02 6.30e+00 3.30e+00 6.00e+00 2.50e+00 2.00e+00]\n",
      " [1.02e+02 5.80e+00 2.70e+00 5.10e+00 1.90e+00 2.00e+00]\n",
      " [1.03e+02 7.10e+00 3.00e+00 5.90e+00 2.10e+00 2.00e+00]\n",
      " [1.04e+02 6.30e+00 2.90e+00 5.60e+00 1.80e+00 2.00e+00]\n",
      " [1.05e+02 6.50e+00 3.00e+00 5.80e+00 2.20e+00 2.00e+00]\n",
      " [1.06e+02 7.60e+00 3.00e+00 6.60e+00 2.10e+00 2.00e+00]\n",
      " [1.07e+02 4.90e+00 2.50e+00 4.50e+00 1.70e+00 2.00e+00]\n",
      " [1.08e+02 7.30e+00 2.90e+00 6.30e+00 1.80e+00 2.00e+00]\n",
      " [1.09e+02 6.70e+00 2.50e+00 5.80e+00 1.80e+00 2.00e+00]\n",
      " [1.10e+02 7.20e+00 3.60e+00 6.10e+00 2.50e+00 2.00e+00]\n",
      " [1.11e+02 6.50e+00 3.20e+00 5.10e+00 2.00e+00 2.00e+00]\n",
      " [1.12e+02 6.40e+00 2.70e+00 5.30e+00 1.90e+00 2.00e+00]\n",
      " [1.13e+02 6.80e+00 3.00e+00 5.50e+00 2.10e+00 2.00e+00]\n",
      " [1.14e+02 5.70e+00 2.50e+00 5.00e+00 2.00e+00 2.00e+00]\n",
      " [1.15e+02 5.80e+00 2.80e+00 5.10e+00 2.40e+00 2.00e+00]\n",
      " [1.16e+02 6.40e+00 3.20e+00 5.30e+00 2.30e+00 2.00e+00]\n",
      " [1.17e+02 6.50e+00 3.00e+00 5.50e+00 1.80e+00 2.00e+00]\n",
      " [1.18e+02 7.70e+00 3.80e+00 6.70e+00 2.20e+00 2.00e+00]\n",
      " [1.19e+02 7.70e+00 2.60e+00 6.90e+00 2.30e+00 2.00e+00]\n",
      " [1.20e+02 6.00e+00 2.20e+00 5.00e+00 1.50e+00 2.00e+00]\n",
      " [1.21e+02 6.90e+00 3.20e+00 5.70e+00 2.30e+00 2.00e+00]\n",
      " [1.22e+02 5.60e+00 2.80e+00 4.90e+00 2.00e+00 2.00e+00]\n",
      " [1.23e+02 7.70e+00 2.80e+00 6.70e+00 2.00e+00 2.00e+00]\n",
      " [1.24e+02 6.30e+00 2.70e+00 4.90e+00 1.80e+00 2.00e+00]\n",
      " [1.25e+02 6.70e+00 3.30e+00 5.70e+00 2.10e+00 2.00e+00]\n",
      " [1.26e+02 7.20e+00 3.20e+00 6.00e+00 1.80e+00 2.00e+00]\n",
      " [1.27e+02 6.20e+00 2.80e+00 4.80e+00 1.80e+00 2.00e+00]\n",
      " [1.28e+02 6.10e+00 3.00e+00 4.90e+00 1.80e+00 2.00e+00]\n",
      " [1.29e+02 6.40e+00 2.80e+00 5.60e+00 2.10e+00 2.00e+00]\n",
      " [1.30e+02 7.20e+00 3.00e+00 5.80e+00 1.60e+00 2.00e+00]\n",
      " [1.31e+02 7.40e+00 2.80e+00 6.10e+00 1.90e+00 2.00e+00]\n",
      " [1.32e+02 7.90e+00 3.80e+00 6.40e+00 2.00e+00 2.00e+00]\n",
      " [1.33e+02 6.40e+00 2.80e+00 5.60e+00 2.20e+00 2.00e+00]\n",
      " [1.34e+02 6.30e+00 2.80e+00 5.10e+00 1.50e+00 2.00e+00]\n",
      " [1.35e+02 6.10e+00 2.60e+00 5.60e+00 1.40e+00 2.00e+00]\n",
      " [1.36e+02 7.70e+00 3.00e+00 6.10e+00 2.30e+00 2.00e+00]\n",
      " [1.37e+02 6.30e+00 3.40e+00 5.60e+00 2.40e+00 2.00e+00]\n",
      " [1.38e+02 6.40e+00 3.10e+00 5.50e+00 1.80e+00 2.00e+00]\n",
      " [1.39e+02 6.00e+00 3.00e+00 4.80e+00 1.80e+00 2.00e+00]\n",
      " [1.40e+02 6.90e+00 3.10e+00 5.40e+00 2.10e+00 2.00e+00]\n",
      " [1.41e+02 6.70e+00 3.10e+00 5.60e+00 2.40e+00 2.00e+00]\n",
      " [1.42e+02 6.90e+00 3.10e+00 5.10e+00 2.30e+00 2.00e+00]\n",
      " [1.43e+02 5.80e+00 2.70e+00 5.10e+00 1.90e+00 2.00e+00]\n",
      " [1.44e+02 6.80e+00 3.20e+00 5.90e+00 2.30e+00 2.00e+00]\n",
      " [1.45e+02 6.70e+00 3.30e+00 5.70e+00 2.50e+00 2.00e+00]\n",
      " [1.46e+02 6.70e+00 3.00e+00 5.20e+00 2.30e+00 2.00e+00]\n",
      " [1.47e+02 6.30e+00 2.50e+00 5.00e+00 1.90e+00 2.00e+00]\n",
      " [1.48e+02 6.50e+00 3.00e+00 5.20e+00 2.00e+00 2.00e+00]\n",
      " [1.49e+02 6.20e+00 3.40e+00 5.40e+00 2.30e+00 2.00e+00]\n",
      " [1.50e+02 5.90e+00 3.00e+00 5.10e+00 1.80e+00 2.00e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "data = np.genfromtxt ('iris.csv', delimiter=\",\")\n",
    "print (data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "x = data[:, 1 : 5]\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmean = KMeans(n_clusters = 3).fit(x)\n",
    "kmean.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmean.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.006     , 3.418     , 1.464     , 0.244     ],\n",
       "       [5.9016129 , 2.7483871 , 4.39354839, 1.43387097],\n",
       "       [6.85      , 3.07368421, 5.74210526, 2.07105263]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmean.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_reset():\n",
    "    try:\n",
    "        sess.close()\n",
    "    except:\n",
    "        pass\n",
    "    tf.reset_default_graph()\n",
    "    return tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf_reset()\n",
    "input_ph = tf.placeholder(dtype=tf.float32, shape=[None, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "y = data[:,5]\n",
    "print(y)\n",
    "output_ph = tf.one_hot(indices = y,depth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "W0 = tf.get_variable(name='w0',shape=[4,8],initializer=tf.initializers.random_normal())\n",
    "W1 = tf.get_variable(name='w1',shape=[8,4],initializer=tf.initializers.random_normal())\n",
    "W2 = tf.get_variable(name='w2',shape=[4,3],initializer=tf.initializers.random_normal())\n",
    "\n",
    "weights = [W0,W1,W2]\n",
    "activation = [tf.sigmoid,tf.sigmoid,None]\n",
    "\n",
    "layer = input_ph\n",
    "for W, activation in zip(weights, activation):\n",
    "        layer = tf.matmul(layer, W)\n",
    "        if activation is not None:\n",
    "            layer = activation(layer)\n",
    "            \n",
    "output_pred = layer\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "mse = tf.reduce_mean(0.5 * tf.square(output_pred - output_ph))\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(mse)\n",
    "for i in range(3000):\n",
    "    _,loss = sess.run([opt,mse],feed_dict={input_ph : x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = sess.run(output_pred,feed_dict={input_ph:x})\n",
    "pred = np.argmax(pred,1)\n",
    "np.mean(pred == y) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
